{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-1.1.3-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.46.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.19.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.1.4)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.0.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.19.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.46.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from transformers) (20.7)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.11.1-py38-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.19.2)\n",
      "Collecting pyarrow>=0.17.1\n",
      "  Downloading pyarrow-2.0.0-cp38-cp38-manylinux2014_x86_64.whl (17.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.8 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2020.11.13-cp38-cp38-manylinux2014_x86_64.whl (738 kB)\n",
      "\u001b[K     |████████████████████████████████| 738 kB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.25.8)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.14.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.46.0)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp38-cp38-manylinux2010_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.0-cp38-cp38-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=498080113d1f8c140c74c78546554bb3ce019819e229033609a15dfe695caa60\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/7b/78/f4/27d43a65043e1b75dbddaa421b573eddc67e712be4b1c80677\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, dill, xxhash, tokenizers, sacremoses, pyarrow, multiprocess, transformers, datasets\n",
      "Successfully installed datasets-1.1.3 dill-0.3.3 multiprocess-0.70.11.1 pyarrow-2.0.0 regex-2020.11.13 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0 xxhash-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nonechucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    glue_compute_metrics,\n",
    "    PhobertTokenizer\n",
    ")\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from textprocessor.normalization import VncorenlpTokenizer\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from readers.DrQA import data, model, module as reader_module\n",
    "from readers.DrQA import config as cfg\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "# import nonechucks as nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, pos_vocab, ner_vocab, max_seq_length, encodings, aug=None):\n",
    "        self.encodings = encodings\n",
    "        self.aug = aug\n",
    "        self.len_enc = len(self.encodings['labels'])\n",
    "        self.vocab = vocab\n",
    "        self.ner_vocab =  ner_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        if aug is not None:\n",
    "            self.len_aug = len(self.aug['labels'])\n",
    "            print('len aug', self.len_aug)\n",
    "    \n",
    "    def _single_toksnfeat2ids(self, text_toks:str, pos_toks:str, ner_toks:str):\n",
    "        try:\n",
    "            text_toks = text_toks.strip().lower().split(' ')\n",
    "            pos_toks = pos_toks.strip().lower().split(' ')\n",
    "            ner_toks = ner_toks.strip().lower().split(' ')\n",
    "        except Exception:\n",
    "            print('..........')\n",
    "            print(text_toks, pos_toks, ner_toks)\n",
    "        tok_ids = []\n",
    "        pos_ids = []\n",
    "        ner_ids = []\n",
    "        for i in range(len(text_toks)):\n",
    "            if i >= self.max_seq_length:\n",
    "                break\n",
    "            try:\n",
    "                tok_ids.append(self.vocab[text_toks[i]])\n",
    "                pos_ids.append(self.pos_vocab[pos_toks[i]])\n",
    "                ner_ids.append(self.ner_vocab[ner_toks[i]])\n",
    "            except:\n",
    "                print('sda..........')\n",
    "                \n",
    "                print(text_toks, pos_toks, ner_toks)\n",
    "\n",
    "        return tok_ids, pos_ids, ner_ids\n",
    "    \n",
    "    def idsitem(self, item):\n",
    "        x1, pos1, ner1 = self._single_toksnfeat2ids(item['x1'], item['x1_f'][0], item['x1_f'][1])\n",
    "        x2, pos2, ner2 = self._single_toksnfeat2ids(item['x2'], item['x2_f'][0], item['x2_f'][1])\n",
    "        iitem = {'x1': x1, 'x2': x2, 'x1_f': [pos1, ner1], 'x2_f': [pos2, ner2]}        \n",
    "        return iitem\n",
    "    \n",
    "    def _get_non_aug(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items() if key != 'labels'}\n",
    "        item = self.idsitem(item)\n",
    "        item['labels'] = int(self.encodings['labels'][idx])\n",
    "        return item\n",
    "    \n",
    "    def _get_aug(self, idx):\n",
    "        try:\n",
    "            item = {key: val[idx] for key, val in self.aug.items() if key != 'labels'}\n",
    "            item = self.idsitem(item)\n",
    "            item['labels'] = int(self.aug['labels'][idx])\n",
    "        except:\n",
    "            idx = 0\n",
    "            item = {key: val[idx] for key, val in self.aug.items() if key != 'labels'}\n",
    "            item = self.idsitem(item)\n",
    "            item['labels'] = int(self.aug['labels'][idx])\n",
    "        return item\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.aug is not None and torch.rand((1, )) < 0.2:\n",
    "            return self._get_aug(idx % self.len_aug)\n",
    "        else:\n",
    "            return self._get_non_aug(idx % self.len_enc)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.aug is None:\n",
    "            return self.len_enc\n",
    "        else:\n",
    "            return self.len_enc + self.len_aug\n",
    "            \n",
    "    def lengths(self):\n",
    "        ret = [(len(ex[0]), len(ex[1]))\n",
    "                for ex in zip(self.encodings['x1'], self.encodings['x2'])]\n",
    "        rm = []\n",
    "        if self.aug is not None:\n",
    "            for ex in zip(self.encodings['x1'], self.encodings['x2']):\n",
    "                try:\n",
    "                    ret.append((len(ex[0]), len(ex[1])))\n",
    "                except:\n",
    "                    continue\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _pad(l, val, max_len):\n",
    "    l += [val]*(max_len - len(l))\n",
    "    return l\n",
    "def _pad_group(g):\n",
    "    max_len = max([len(x) for x in g[0]])\n",
    "    mask = []\n",
    "    for i in range(len(g[0])):\n",
    "        mask.append([0]*len(g[0][i]) + [1]*(max_len - len(g[0][i])))\n",
    "        _pad(g[0][i], 1, max_len)\n",
    "        _pad(g[1][i][0], 1, max_len)\n",
    "        _pad(g[1][i][1], 1, max_len)\n",
    "#         print(g)\n",
    "    return mask\n",
    "def pad(batch):\n",
    "#     print(batch)\n",
    "    features = ['x1','x1_f', 'x2', 'x2_f', 'labels']\n",
    "    d = {f:[] for f in features}\n",
    "    for i in batch:\n",
    "        for f in features:\n",
    "            d[f].append(i[f])\n",
    "    q = [d['x1'], d['x1_f']]\n",
    "    p = [d['x2'], d['x2_f']]\n",
    "    d['x1_mask'] = _pad_group(q)\n",
    "    d['x2_mask'] = _pad_group(p)\n",
    "    for k, v in d.items():\n",
    "        try:\n",
    "            d[k] = torch.tensor(v)\n",
    "        except Exception:\n",
    "            print(v)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortedBatchSampler(Sampler):\n",
    "\n",
    "    def __init__(self, lengths, batch_size, shuffle=True):\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        lengths = np.array([(-l[0], -l[1], np.random.random()) for l in self.lengths],dtype=[('l1', np.int_), ('l2', np.int_), ('rand', np.float_)])\n",
    "        indices = np.argsort(lengths, order=('l1', 'l2', 'rand'))\n",
    "        batches = [indices[i:i + self.batch_size]\n",
    "                   for i in range(0, len(indices), self.batch_size)]\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(batches)\n",
    "        return iter([i for batch in batches for i in batch])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lengths)\n",
    "\n",
    "\n",
    "class GensimDataModule(pl.LightningDataModule):\n",
    "    tok_field = 'toks'\n",
    "    pos_field = 'pos'\n",
    "    ner_field = 'ner'\n",
    "    \n",
    "    q_pref = 'q_'\n",
    "    t_pref = 't_'\n",
    "    num_labels = 2\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab,\n",
    "        pos_vocab,\n",
    "        ner_vocab,\n",
    "        max_seq_length: int = 128,\n",
    "        train_batch_size: int = 32,\n",
    "        eval_batch_size: int = 32,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "\n",
    "    def filtnan(self, df):\n",
    "        tmp = df.replace(np.nan, '', regex=True)\n",
    "        return tmp[(tmp['t_toks'] != '') & (tmp['q_toks'] != '')]\n",
    "    \n",
    "    def setup(self, stage, df_ls):\n",
    "        \n",
    "        train_df = df_ls[0]\n",
    "        \n",
    "        valid_df = df_ls[1]\n",
    "        if len(df_ls) == 3:\n",
    "            aug_df = df_ls[2]\n",
    "            self.dataset = {\n",
    "                \"train\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(train_df), self.convert_to_features(aug_df)),\n",
    "                \"validation\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(valid_df)),\n",
    "                }\n",
    "        else:\n",
    "            self.dataset = {\n",
    "                \"train\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(train_df)),\n",
    "                \"validation\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(valid_df)),\n",
    "                }\n",
    "        self.eval_splits = [\"validation\"]\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        sampler = SortedBatchSampler(\n",
    "            self.dataset['train'].lengths(),\n",
    "            self.train_batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        return DataLoader(self.dataset['train'], batch_size=self.train_batch_size, collate_fn=pad, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "    def val_dataloader(self):\n",
    "        sampler = SortedBatchSampler(\n",
    "            self.dataset['validation'].lengths(),\n",
    "            self.eval_batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        return DataLoader(self.dataset['validation'], batch_size=self.eval_batch_size, collate_fn=pad, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.dataset['validation'], batch_size=self.eval_batch_size, collate_fn=pad,num_workers=4, pin_memory=True)\n",
    "    \n",
    "    def tok2id(self, tokens):\n",
    "        return tensor([self.vocab[tok.lower()] for tok in tokens], dtype=torch.int64)\n",
    "    def ids2toks(self, ids):\n",
    "        return ' '.join([self.vocab[ind] for ind in ids.tolist()])\n",
    "    \n",
    "    def _single_toksnfeat2ids(self, text_toks:str, pos_toks:str, ner_toks:str):\n",
    "        text_toks = text_toks.strip().lower().split(' ')\n",
    "        pos_toks = pos_toks.strip().lower().split(' ')\n",
    "        ner_toks = ner_toks.strip().lower().split(' ')\n",
    "        tok_ids = []\n",
    "        pos_ids = []\n",
    "        ner_ids = []\n",
    "        for i in range(len(text_toks)):\n",
    "            if i >= self.max_seq_length:\n",
    "                break\n",
    "            tok_ids.append(self.vocab[text_toks[i]])\n",
    "            pos_ids.append(self.pos_vocab[pos_toks[i]])\n",
    "            ner_ids.append(self.ner_vocab[ner_toks[i]])\n",
    "        return tok_ids, pos_ids, ner_ids\n",
    "\n",
    "    \n",
    "    def toksnfeat2ids(self, tok, pos, ner, padding=True):\n",
    "        assert len(tok) == len(pos) and len(tok) == len(ner)\n",
    "        longest = 0\n",
    "        batch_tok_ids = []\n",
    "        batch_pos_ids = []\n",
    "        batch_ner_ids = []\n",
    "        batch_mask = []\n",
    "        for i in range(len(tok)):\n",
    "            try:\n",
    "                if len(tok[i]) <= 0:\n",
    "                    continue\n",
    "                tok_ids, pos_ids, ner_ids = self._single_toksnfeat2ids(tok[i], pos[i], ner[i])\n",
    "                batch_tok_ids.append(tok_ids)\n",
    "                batch_pos_ids.append(pos_ids)\n",
    "                batch_ner_ids.append(ner_ids)\n",
    "                batch_mask.append([0]*len(tok_ids))\n",
    "            except TypeError:\n",
    "#                 print('Skip ', tok[i])\n",
    "                continue\n",
    "        return batch_tok_ids, batch_pos_ids, batch_ner_ids, batch_mask\n",
    "        \n",
    "    def convert_to_features(self, example_batch, indices=None):\n",
    "        features = {\n",
    "            'x1': example_batch[self.q_pref + self.tok_field].tolist(),\n",
    "            'x1_f': list(zip(example_batch[self.q_pref + self.pos_field], example_batch[self.q_pref + self.ner_field])),\n",
    "            'x2': example_batch[self.t_pref + self.tok_field].tolist(),\n",
    "            'x2_f': list(zip(example_batch[self.t_pref + self.pos_field], example_batch[self.t_pref + self.ner_field])),\n",
    "            'labels': example_batch['label']\n",
    "        }\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_path = 'wordembedding/pretrain_models/word2vec/baomoi.window2.vn.model.bin'\n",
    "wv = KeyedVectors.load_word2vec_format(wv_path,binary=True)\n",
    "vocab = data.W2VVocab(['<unk>', '<pad>', '<cls>'], 0, 1, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_vocab = data.ReaderVocab.from_file('dataset/vocabs/train_feat_ner_vocab.txt')\n",
    "ner_vocab.UNK='<unk>'\n",
    "pos_vocab = data.ReaderVocab.from_file('dataset/vocabs/train_feat_pos_vocab.txt')\n",
    "pos_vocab.UNK='<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in_train = []\n",
    "with open('dataset/vocabs/zlqa_token_list.txt', 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        w_in_train.append(line.split(' ')[-1][:-1].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = GensimDataModule(vocab, pos_vocab, ner_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.prepare_data()\n",
    "# dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args=None):\n",
    "    parser = ArgumentParser()\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    parser = GensimDataModule.add_argparse_args(parser)\n",
    "    parser = DrQA.add_model_specific_args(parser)\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    return parser.parse_args(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = cfg.Args()\n",
    "# args.max_len = 256\n",
    "args.hidden_size = 512\n",
    "args.context_layers = 3\n",
    "args.question_layers = 2\n",
    "args.concat_rnn_layers = True\n",
    "args.dropout_rnn = 0.2\n",
    "args.dropout_emb = 0.1\n",
    "args.layernorm_emb = True\n",
    "args.dropout_rnn_output = True\n",
    "args.embedding_dim = 300\n",
    "args.num_features = 2\n",
    "\n",
    "mocked_args = \"\"\"\n",
    "    --max_epochs 20\n",
    "    --gpus 1\n",
    "    --learning_rate 2e-3\n",
    "    --adam_epsilon 1e-8\n",
    "    --weight_decay 1e-1\n",
    "    --warmup_steps 200\n",
    "    --max_seq_length 256\n",
    "    --train_batch_size 64\n",
    "    --eval_batch_size 64\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margs = parse_args(mocked_args)\n",
    "pl.seed_everything(margs.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/qaset/train_feature_set2.csv').sample(frac=1).reset_index(drop=True)\n",
    "aug_df = pd.read_csv('dataset/qaset/aug_feature_set2.csv').sample(frac=1).reset_index(drop=True)\n",
    "valid_df = pd.read_csv('dataset/qaset/valid_feature_set2.csv').sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len aug 1 105492\n",
      "len aug 105492\n"
     ]
    }
   ],
   "source": [
    "dm = GensimDataModule.from_argparse_args(margs,vocab=vocab,pos_vocab=pos_vocab, ner_vocab=ner_vocab)\n",
    "dm.prepare_data()\n",
    "dm.setup('fit', [train_df, valid_df, aug_df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedding\n",
      "Loaded 24631 embeddings (100.00%)\n"
     ]
    }
   ],
   "source": [
    "model = DrQA(args, vocab, [len(pos_vocab), len(ner_vocab)], **vars(margs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(dm.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger('tb_logs', name='DrQA01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs 1 train, val, test batch and program ends\n",
    "# trainer = pl.Trainer.from_argparse_args(margs, fast_dev_run=True, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer.from_argparse_args(margs, logger=logger, auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | embedding         | EmbeddingModule  | 131 M \n",
      "1 | embedding_feature | ModuleList       | 41    \n",
      "2 | network           | RnnDocReader     | 33.2 M\n",
      "3 | loss_fct          | CrossEntropyLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51535618c4848808353fbd47a670f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early due to diverging loss.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder = trainer.tuner.lr_find(model, train_dataloader=dm.train_dataloader())\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hparams.lr = lr_finder.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | embedding         | EmbeddingModule  | 131 M \n",
      "1 | embedding_feature | ModuleList       | 41    \n",
      "2 | network           | RnnDocReader     | 33.2 M\n",
      "3 | loss_fct          | CrossEntropyLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5cd3831cd64a2ab3b0a7d393fcd1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_vocab.UNK='<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_vocab['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
