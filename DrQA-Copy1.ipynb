{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -y -c conda-forge transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    glue_compute_metrics,\n",
    "    PhobertTokenizer\n",
    ")\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from textprocessor.normalization import VncorenlpTokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from readers.DrQA_Attention import data, model as reader_module, layers\n",
    "from readers.DrQA_Attention import config as cfg\n",
    "from readers.DrQA_Attention.lightningmodule import DrQA as DrQA_attn\n",
    "from readers.DrQA.lightningmodule import DrQA\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, pos_vocab, ner_vocab, max_seq_length, encodings, aug=None):\n",
    "        self.encodings = encodings\n",
    "        self.aug = aug\n",
    "        self.len_enc = len(self.encodings['labels'])\n",
    "        self.vocab = vocab\n",
    "        self.ner_vocab =  ner_vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        if aug is not None:\n",
    "            self.len_aug = len(self.aug['labels'])\n",
    "            print('len aug', self.len_aug)\n",
    "    \n",
    "    def _single_toksnfeat2ids(self, text_toks:str, pos_toks:str, ner_toks:str):\n",
    "        try:\n",
    "            text_toks = text_toks.strip().lower().split(' ')\n",
    "            pos_toks = pos_toks.strip().lower().split(' ')\n",
    "            ner_toks = ner_toks.strip().lower().split(' ')\n",
    "        except Exception:\n",
    "            print('..........')\n",
    "            print(text_toks, pos_toks, ner_toks)\n",
    "        tok_ids = []\n",
    "        pos_ids = []\n",
    "        ner_ids = []\n",
    "        for i in range(len(text_toks)):\n",
    "            if i >= self.max_seq_length:\n",
    "                break\n",
    "            try:\n",
    "                tok_ids.append(self.vocab[text_toks[i]])\n",
    "                pos_ids.append(self.pos_vocab[pos_toks[i]])\n",
    "                ner_ids.append(self.ner_vocab[ner_toks[i]])\n",
    "            except:\n",
    "                print('sda..........')\n",
    "                \n",
    "                print(text_toks, pos_toks, ner_toks)\n",
    "\n",
    "        return tok_ids, pos_ids, ner_ids\n",
    "    \n",
    "    def idsitem(self, item):\n",
    "        x1, pos1, ner1 = self._single_toksnfeat2ids(item['x1'], item['x1_f'][0], item['x1_f'][1])\n",
    "        x2, pos2, ner2 = self._single_toksnfeat2ids(item['x2'], item['x2_f'][0], item['x2_f'][1])\n",
    "        iitem = {'x1': x1, 'x2': x2, 'x1_f': [pos1, ner1], 'x2_f': [pos2, ner2]}        \n",
    "        return iitem\n",
    "    \n",
    "    def _get_non_aug(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items() if key != 'labels'}\n",
    "        item = self.idsitem(item)\n",
    "        item['labels'] = int(self.encodings['labels'][idx])\n",
    "        return item\n",
    "    \n",
    "    def _get_aug(self, idx):\n",
    "        try:\n",
    "            item = {key: val[idx] for key, val in self.aug.items() if key != 'labels'}\n",
    "            item = self.idsitem(item)\n",
    "            item['labels'] = int(self.aug['labels'][idx])\n",
    "        except:\n",
    "            idx = 0\n",
    "            item = {key: val[idx] for key, val in self.aug.items() if key != 'labels'}\n",
    "            item = self.idsitem(item)\n",
    "            item['labels'] = int(self.aug['labels'][idx])\n",
    "        return item\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.aug is not None and torch.rand((1, )) < 0.2:\n",
    "            return self._get_aug(idx % self.len_aug)\n",
    "        else:\n",
    "            return self._get_non_aug(idx % self.len_enc)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.aug is None:\n",
    "            return self.len_enc\n",
    "        else:\n",
    "            return self.len_enc + self.len_aug\n",
    "            \n",
    "    def lengths(self):\n",
    "        ret = [(len(ex[0]), len(ex[1]))\n",
    "                for ex in zip(self.encodings['x1'], self.encodings['x2'])]\n",
    "        rm = []\n",
    "        if self.aug is not None:\n",
    "            for ex in zip(self.encodings['x1'], self.encodings['x2']):\n",
    "                try:\n",
    "                    ret.append((len(ex[0]), len(ex[1])))\n",
    "                except:\n",
    "                    continue\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _pad(l, val, max_len):\n",
    "    l += [val]*(max_len - len(l))\n",
    "    return l\n",
    "def _pad_group(g):\n",
    "    max_len = max([len(x) for x in g[0]])\n",
    "    mask = []\n",
    "    for i in range(len(g[0])):\n",
    "        mask.append([0]*len(g[0][i]) + [1]*(max_len - len(g[0][i])))\n",
    "        _pad(g[0][i], 1, max_len)\n",
    "        _pad(g[1][i][0], 1, max_len)\n",
    "        _pad(g[1][i][1], 1, max_len)\n",
    "#         print(g)\n",
    "    return mask\n",
    "def pad(batch):\n",
    "#     print(batch)\n",
    "    features = ['x1','x1_f', 'x2', 'x2_f', 'labels']\n",
    "    d = {f:[] for f in features}\n",
    "    for i in batch:\n",
    "        for f in features:\n",
    "            d[f].append(i[f])\n",
    "    q = [d['x1'], d['x1_f']]\n",
    "    p = [d['x2'], d['x2_f']]\n",
    "    d['x1_mask'] = _pad_group(q)\n",
    "    d['x2_mask'] = _pad_group(p)\n",
    "    for k, v in d.items():\n",
    "        try:\n",
    "            d[k] = torch.tensor(v)\n",
    "        except Exception:\n",
    "            print(v)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortedBatchSampler(Sampler):\n",
    "\n",
    "    def __init__(self, lengths, batch_size, shuffle=True):\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        lengths = np.array([(-l[0], -l[1], np.random.random()) for l in self.lengths],dtype=[('l1', np.int_), ('l2', np.int_), ('rand', np.float_)])\n",
    "        indices = np.argsort(lengths, order=('l1', 'l2', 'rand'))\n",
    "        batches = [indices[i:i + self.batch_size]\n",
    "                   for i in range(0, len(indices), self.batch_size)]\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(batches)\n",
    "        return iter([i for batch in batches for i in batch])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lengths)\n",
    "\n",
    "\n",
    "class GensimDataModule(pl.LightningDataModule):\n",
    "    tok_field = 'toks'\n",
    "    pos_field = 'pos'\n",
    "    ner_field = 'ner'\n",
    "    \n",
    "    q_pref = 'q_'\n",
    "    t_pref = 't_'\n",
    "    num_labels = 2\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab,\n",
    "        pos_vocab,\n",
    "        ner_vocab,\n",
    "        max_seq_length: int = 128,\n",
    "        train_batch_size: int = 32,\n",
    "        eval_batch_size: int = 32,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        self.pos_vocab = pos_vocab\n",
    "        self.ner_vocab = ner_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "\n",
    "    def filtnan(self, df):\n",
    "        tmp = df.replace(np.nan, '', regex=True)\n",
    "        return tmp[(tmp['t_toks'] != '') & (tmp['q_toks'] != '')]\n",
    "    \n",
    "    def setup(self, stage, df_ls):\n",
    "        \n",
    "        train_df = df_ls[0]\n",
    "        \n",
    "        valid_df = df_ls[1]\n",
    "        if len(df_ls) == 3:\n",
    "            aug_df = df_ls[2]\n",
    "            self.dataset = {\n",
    "                \"train\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(train_df), self.convert_to_features(aug_df)),\n",
    "                \"validation\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(valid_df)),\n",
    "                }\n",
    "        else:\n",
    "            self.dataset = {\n",
    "                \"train\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(train_df)),\n",
    "                \"validation\": SimpleDataset(self.vocab, self.pos_vocab, self.ner_vocab, self.max_seq_length, self.convert_to_features(valid_df)),\n",
    "                }\n",
    "        self.eval_splits = [\"validation\"]\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    def train_dataloader(self):\n",
    "        sampler = SortedBatchSampler(\n",
    "            self.dataset['train'].lengths(),\n",
    "            self.train_batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        return DataLoader(self.dataset['train'], batch_size=self.train_batch_size, collate_fn=pad, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "    def val_dataloader(self):\n",
    "        sampler = SortedBatchSampler(\n",
    "            self.dataset['validation'].lengths(),\n",
    "            self.eval_batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        return DataLoader(self.dataset['validation'], batch_size=self.eval_batch_size, collate_fn=pad, sampler=sampler, num_workers=4, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.dataset['validation'], batch_size=self.eval_batch_size, collate_fn=pad,num_workers=4, pin_memory=True)\n",
    "    \n",
    "    def tok2id(self, tokens):\n",
    "        return tensor([self.vocab[tok.lower()] for tok in tokens], dtype=torch.int64)\n",
    "    def ids2toks(self, ids):\n",
    "        return ' '.join([self.vocab[ind] for ind in ids.tolist()])\n",
    "    \n",
    "    def _single_toksnfeat2ids(self, text_toks:str, pos_toks:str, ner_toks:str):\n",
    "        text_toks = text_toks.strip().lower().split(' ')\n",
    "        pos_toks = pos_toks.strip().lower().split(' ')\n",
    "        ner_toks = ner_toks.strip().lower().split(' ')\n",
    "        tok_ids = []\n",
    "        pos_ids = []\n",
    "        ner_ids = []\n",
    "        for i in range(len(text_toks)):\n",
    "            if i >= self.max_seq_length:\n",
    "                break\n",
    "            tok_ids.append(self.vocab[text_toks[i]])\n",
    "            pos_ids.append(self.pos_vocab[pos_toks[i]])\n",
    "            ner_ids.append(self.ner_vocab[ner_toks[i]])\n",
    "        return tok_ids, pos_ids, ner_ids\n",
    "\n",
    "    \n",
    "    def toksnfeat2ids(self, tok, pos, ner, padding=True):\n",
    "        assert len(tok) == len(pos) and len(tok) == len(ner)\n",
    "        longest = 0\n",
    "        batch_tok_ids = []\n",
    "        batch_pos_ids = []\n",
    "        batch_ner_ids = []\n",
    "        batch_mask = []\n",
    "        for i in range(len(tok)):\n",
    "            try:\n",
    "                if len(tok[i]) <= 0:\n",
    "                    continue\n",
    "                tok_ids, pos_ids, ner_ids = self._single_toksnfeat2ids(tok[i], pos[i], ner[i])\n",
    "                batch_tok_ids.append(tok_ids)\n",
    "                batch_pos_ids.append(pos_ids)\n",
    "                batch_ner_ids.append(ner_ids)\n",
    "                batch_mask.append([0]*len(tok_ids))\n",
    "            except TypeError:\n",
    "#                 print('Skip ', tok[i])\n",
    "                continue\n",
    "        return batch_tok_ids, batch_pos_ids, batch_ner_ids, batch_mask\n",
    "        \n",
    "    def convert_to_features(self, example_batch, indices=None):\n",
    "        features = {\n",
    "            'x1': example_batch[self.q_pref + self.tok_field].tolist(),\n",
    "            'x1_f': list(zip(example_batch[self.q_pref + self.pos_field], example_batch[self.q_pref + self.ner_field])),\n",
    "            'x2': example_batch[self.t_pref + self.tok_field].tolist(),\n",
    "            'x2_f': list(zip(example_batch[self.t_pref + self.pos_field], example_batch[self.t_pref + self.ner_field])),\n",
    "            'labels': example_batch['label']\n",
    "        }\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_path = 'wordembedding/pretrain_models/word2vec/baomoi.window2.vn.model.bin'\n",
    "wv = KeyedVectors.load_word2vec_format(wv_path,binary=True)\n",
    "vocab = data.W2VVocab(['<unk>', '<pad>', '<cls>'], 0, 1, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_vocab = data.ReaderVocab.from_file('dataset/vocabs/train_feat_ner_vocab.txt')\n",
    "ner_vocab.UNK='<unk>'\n",
    "pos_vocab = data.ReaderVocab.from_file('dataset/vocabs/train_feat_pos_vocab.txt')\n",
    "pos_vocab.UNK='<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in_train = []\n",
    "with open('dataset/vocabs/zlqa_token_list.txt', 'r') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        w_in_train.append(line.split(' ')[-1][:-1].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args=None):\n",
    "    parser = ArgumentParser()\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    parser = GensimDataModule.add_argparse_args(parser)\n",
    "    parser = DrQA.add_model_specific_args(parser)\n",
    "    parser.add_argument('--seed', type=int, default=42)\n",
    "    return parser.parse_args(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_normal = cfg.Args()\n",
    "# args.max_len = 256\n",
    "args_normal.hidden_size = 512\n",
    "args_normal.context_layers = 3\n",
    "args_normal.pre_context_layers = 2\n",
    "args_normal.question_layers = 2\n",
    "args_normal.num_encodes = 3\n",
    "args_normal.num_heads = 6\n",
    "args_normal.concat_rnn_layers = True\n",
    "args_normal.dropout_rnn = 0.2\n",
    "args_normal.dropout_emb = 0.1\n",
    "args_normal.layernorm_emb = True\n",
    "args_normal.dropout_rnn_output = True\n",
    "args_normal.embedding_dim = 300\n",
    "args_normal.num_features = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = cfg.Args()\n",
    "args.hidden_size = 512\n",
    "args.context_layers = 1\n",
    "args.pre_context_layers = 1\n",
    "args.question_layers = 2\n",
    "args.num_encodes = 4\n",
    "args.num_heads = 8\n",
    "args.concat_rnn_layers = True\n",
    "args.dropout_rnn = 0.2\n",
    "args.dropout_emb = 0.1\n",
    "args.layernorm_emb = True\n",
    "args.dropout_rnn_output = True\n",
    "args.embedding_dim = 300\n",
    "args.num_features = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mocked_args = \"\"\"\n",
    "    --max_epochs 5\n",
    "    --gpus 1\n",
    "    --learning_rate 2e-3\n",
    "    --adam_epsilon 1e-8\n",
    "    --weight_decay 1e-1\n",
    "    --warmup_steps 200\n",
    "    --max_seq_length 256\n",
    "    --train_batch_size 16\n",
    "    --eval_batch_size 16\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margs = parse_args(mocked_args)\n",
    "pl.seed_everything(margs.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/qaset/train_feature_set2.csv').sample(frac=1).reset_index(drop=True)\n",
    "aug_df = pd.read_csv('dataset/qaset/aug_feature_set2.csv').sample(frac=1).reset_index(drop=True)\n",
    "valid_df = pd.read_csv('dataset/qaset/valid_feature_set2.csv').sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len aug 105492\n"
     ]
    }
   ],
   "source": [
    "dm = GensimDataModule.from_argparse_args(margs,vocab=vocab,pos_vocab=pos_vocab, ner_vocab=ner_vocab)\n",
    "dm.prepare_data()\n",
    "dm.setup('fit', [train_df, valid_df, aug_df])\n",
    "# dm.setup('fit', [train_df, valid_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1811"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 29])\n",
      "torch.Size([16, 2, 29])\n",
      "torch.Size([16, 29])\n",
      "torch.Size([16, 110])\n",
      "torch.Size([16, 2, 110])\n",
      "torch.Size([16, 110])\n"
     ]
    }
   ],
   "source": [
    "print(b['x1'].size())\n",
    "print(b['x1_f'].size())\n",
    "print(b['x1_mask'].size())\n",
    "\n",
    "print(b['x2'].size())\n",
    "print(b['x2_f'].size())\n",
    "print(b['x2_mask'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24631 embeddings (100.00%)\n"
     ]
    }
   ],
   "source": [
    "model = DrQA_attn(args, vocab, [len(pos_vocab), len(ner_vocab)], **vars(margs))\n",
    "model.embedding.load_embeddings(w_in_train, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DrQA(\n",
      "  (embedding): EmbeddingModule(\n",
      "    (embedding): Embedding(439057, 300, padding_idx=1)\n",
      "    (layernorm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (embedding_feature): ModuleList(\n",
      "    (0): Embedding(29, 1, padding_idx=1)\n",
      "    (1): Embedding(12, 1, padding_idx=1)\n",
      "  )\n",
      "  (network): RnnDocReader(\n",
      "    (rnn): CustomRNN(\n",
      "      (rnns): ModuleList(\n",
      "        (0): RNNBlock(\n",
      "          (rnn): LSTM(300, 512)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (encodes): ModuleList(\n",
      "      (0): EncodeModule(\n",
      "        (linear1): Linear(in_features=514, out_features=1028, bias=True)\n",
      "        (linear2): Linear(in_features=1028, out_features=514, bias=True)\n",
      "        (norm1): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (mul_head): Multihead(\n",
      "          (heads): ModuleList(\n",
      "            (0): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (1): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (2): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (3): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (4): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (5): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (6): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (7): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (linear_out): Linear(in_features=4112, out_features=514, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (1): EncodeModule(\n",
      "        (linear1): Linear(in_features=514, out_features=1028, bias=True)\n",
      "        (linear2): Linear(in_features=1028, out_features=514, bias=True)\n",
      "        (norm1): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (mul_head): Multihead(\n",
      "          (heads): ModuleList(\n",
      "            (0): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (1): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (2): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (3): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (4): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (5): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (6): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (7): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (linear_out): Linear(in_features=4112, out_features=514, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (2): EncodeModule(\n",
      "        (linear1): Linear(in_features=514, out_features=1028, bias=True)\n",
      "        (linear2): Linear(in_features=1028, out_features=514, bias=True)\n",
      "        (norm1): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (mul_head): Multihead(\n",
      "          (heads): ModuleList(\n",
      "            (0): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (1): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (2): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (3): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (4): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (5): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (6): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (7): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (linear_out): Linear(in_features=4112, out_features=514, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (3): EncodeModule(\n",
      "        (linear1): Linear(in_features=514, out_features=1028, bias=True)\n",
      "        (linear2): Linear(in_features=1028, out_features=514, bias=True)\n",
      "        (norm1): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (mul_head): Multihead(\n",
      "          (heads): ModuleList(\n",
      "            (0): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (1): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (2): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (3): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (4): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (5): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (6): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "            (7): AttnMatch(\n",
      "              (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "              (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (linear_out): Linear(in_features=4112, out_features=514, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pre_context_encodes): EncodeModule(\n",
      "      (linear1): Linear(in_features=514, out_features=1028, bias=True)\n",
      "      (linear2): Linear(in_features=1028, out_features=514, bias=True)\n",
      "      (norm1): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mul_head): Multihead(\n",
      "        (heads): ModuleList(\n",
      "          (0): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (1): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (2): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (3): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (4): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (5): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (6): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (7): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (linear_out): Linear(in_features=4112, out_features=514, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (context_encodes): EncodeModule(\n",
      "      (linear1): Linear(in_features=514, out_features=1028, bias=True)\n",
      "      (linear2): Linear(in_features=1028, out_features=514, bias=True)\n",
      "      (norm1): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mul_head): Multihead(\n",
      "        (heads): ModuleList(\n",
      "          (0): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (1): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (2): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (3): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (4): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (5): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (6): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (7): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (linear_out): Linear(in_features=4112, out_features=514, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (qemb_match): EncodeModule(\n",
      "      (linear1): Linear(in_features=514, out_features=1028, bias=True)\n",
      "      (linear2): Linear(in_features=1028, out_features=514, bias=True)\n",
      "      (norm1): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((514,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (mul_head): Multihead(\n",
      "        (heads): ModuleList(\n",
      "          (0): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (1): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (2): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (3): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (4): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (5): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (6): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "          (7): AttnMatch(\n",
      "            (linear_x): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_y): Linear(in_features=514, out_features=514, bias=True)\n",
      "            (linear_v): Linear(in_features=514, out_features=514, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (linear_out): Linear(in_features=4112, out_features=514, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (ct_head): Linear(in_features=1028, out_features=514, bias=True)\n",
      "    (cmerge_attn): LinearSeqAttn(\n",
      "      (linear): Linear(in_features=514, out_features=1, bias=True)\n",
      "    )\n",
      "    (out): Linear(in_features=514, out_features=2, bias=True)\n",
      "  )\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, (32, 256, args.embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(**next(iter(dm.train_dataloader())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger('tb_logs', name='DrQA_Atten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.experiment.add_graph(model,[b['x1'], b['x1_f'], b['x1_mask'],b['x2'], b['x2_f'], b['x2_mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer.from_argparse_args(margs, logger=logger, auto_lr_find=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Run learning rate finder\n",
    "# lr_finder = trainer.tuner.lr_find(model, train_dataloader=dm.train_dataloader())\n",
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hparams.lr = 1e-3 #lr_finder.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: `train_dataloader` must be implemented to be used with the Lightning Trainer\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# model.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | embedding         | EmbeddingModule  | 131 M \n",
      "1 | embedding_feature | ModuleList       | 41    \n",
      "2 | network           | RnnDocReader     | 68.9 M\n",
      "3 | loss_fct          | CrossEntropyLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34a066859ea40e4b5c8cdbb2377cd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.92 GiB total capacity; 6.58 GiB already allocated; 38.69 MiB free; 6.76 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e95b4f427608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;31m# TRAINING_STEP + TRAINING_STEP_END\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# optimizer step lightningModule hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             self.trainer.accelerator_backend.optimizer_step(\n\u001b[0m\u001b[1;32m    470\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, batch_idx, opt_idx, lambda_closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         model_ref.optimizer_step(\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     def optimizer_zero_grad(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                             result = self.training_step_and_backward(\n\u001b[0m\u001b[1;32m    719\u001b[0m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                                 \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \"\"\"\n\u001b[1;32m    812\u001b[0m         \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_training_step_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_step_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36m__training_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/readers/DrQA_Attention/lightningmodule.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/readers/DrQA_Attention/lightningmodule.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x1_f, x1_mask, x2, x2_f, x2_mask, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mxfembs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mxfembs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfembs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mxfembs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/readers/DrQA_Attention/lightningmodule.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q_emb, q_mask, t_emb, t_mask, q_f, t_f)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# for i in range(self.args.context_layers):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mcontext_hiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_encodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/readers/DrQA_Attention/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, V, K_mask)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mheads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mheads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/readers/DrQA_Attention/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, V, K_mask)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mhead_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mhead_outs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mhead_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/readers/DrQA_Attention/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, Q, K, V, K_mask)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Project vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mQ_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m             \u001b[0mK_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mV_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.92 GiB total capacity; 6.58 GiB already allocated; 38.69 MiB free; 6.76 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "trainer.max_epochs = 3\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = trainer.tuner.lr_find(model, train_dataloader=dm.train_dataloader())\n",
    "model.hparams.lr = min(1e-5, lr_finder.suggestion())\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = trainer.tuner.lr_find(model, train_dataloader=dm.train_dataloader())\n",
    "model.hparams.lr = min(1e-5, lr_finder.suggestion())\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.embedding.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
